The following text document walks through where to obtain the files necessary to contstruct the Master dataset for use in this research project. It additionally highlights the commands used in Linux terminal to parse out the data required from the files

1) In order to obtain an initial reference gene list the following file must be downloaded from Progenomes: https://progenomes.embl.de/data/repGenomes/progenomes3.proteins.representatives.fasta.bz2
This file is decompressed and parsed for just the fasta headers.
bzcat proteins.representatives.fasta.bz2 | pv | bzgrep '^>' > FASTA_HEADERS.txt
The bzgrep command allows for the grepping of just the headers while the pv command allows for monitoring of the command's progress.
sed 's/.GCA.*//' FASTA_HEADERS.TXT This command extracts just the biosampleIDs from the fasta headers file.
sort FASTA_HEADERS.txt | uniq > Biosample_IDs_filtered.txt THis removes all duplicate entrys from the file leaving only the reference list of Biosample IDs.

2) To assemble a large bacterial dataset both the gene and EGGNOG annotations for Proteobacteria, Firmicutes, Bacteriodetes, Actinobacteria and Euryarchaeota were downloaded.
The gene annotations are available at the following links
Proteobacteria: https://progenomes.embl.de/dumpAnnotation.cgi?p=Proteobacteria&t=ga&a=phylum
Firmicutes: https://progenomes.embl.de/dumpAnnotation.cgi?p=Firmicutes&t=ga&a=phylum
Bacteroidetes: https://progenomes.embl.de/dumpAnnotation.cgi?p=Bacteroidetes&t=ga&a=phylum
Actinobacteria: https://progenomes.embl.de/dumpAnnotation.cgi?p=Actinobacteria&t=ga&a=phylum
Euryarchaeota: https://progenomes.embl.de/dumpAnnotation.cgi?p=Euryarchaeota&t=ga&a=phylum

The EGGNOG annotation files are available from the following links
Proteobacteria: https://progenomes.embl.de/dumpAnnotation.cgi?p=Proteobacteria&t=ae&a=phylum
Firmicutes: https://progenomes.embl.de/dumpAnnotation.cgi?p=Firmicutes&t=ae&a=phylum
Bacteroidetes: https://progenomes.embl.de/dumpAnnotation.cgi?p=Bacteroidetes&t=ae&a=phylum
Actinobacteria: https://progenomes.embl.de/dumpAnnotation.cgi?p=Actinobacteria&t=ae&a=phylum
Euryarchaeota: https://progenomes.embl.de/dumpAnnotation.cgi?p=Euryarchaeota&t=ae&a=phylum

3) The EGGNOG annotation files were then parsed to remove duplicates and only leaving a single representative for each bacterial species.
awk 'NR==FNR {Biosample_IDs_filtered[$1]; next} $1 in Biosample_IDs_filtered' Biosample_IDs_filtered.txt Euryarchaeota.eggNOG_groups.tsv > Euryarchaeota.eggNOG_groups_filtered.tsv
This was repeated for each of the 5 separate EGGNOG annotation files.

4) The EGGNOG annotation files were then parsed to remove unnecessary columns
cut -f1-6,9-13,15,18-20  Euryarchaeota.eggNOG_groups_filtered.tsv > Euryarchaeota.dataset.tsv
This left only the Biosample_ID, Gene name, EGGNOG information, KEGG information, COG functional category and predicted protein name.
This command was repeated on each of the eggNOG annotation files.

5) The gene annotation file was then used to add the contig ID to the dataset file.
cut -f1-2 phylum-Euryarchaeota.gene_annotations.tsv > phylum-Euryarchaeota.gene_annotations.filtered.tsv This command was run to give just the Gene ID and contig ID columns.

6) awk -F'\t' 'NR==FNR{a[$1]=$2; next} {print $0, ($2 in a ? a[$2] : "NA")}' OFS='\t' phylum-Euryarchaeota.gene_annotations.filtered.tsv Euryarchaeota.dataset.tsv > output.tsv
This command subsequently matched the Contig ID to the corresponding gene ID file. The output file then lists the Biosample(Genome), Gene ID, Contig ID and additional EGGNOG annotations for each gene.
In order to ease later concatenation of the files this file must also be pruned.
The Column titled NA is subseqeuntly renamed Contig_ID and any rows where no Contig ID was able to be assigned were removed. These represent entries in Progenomes original database which were for various reasons unassigned a Contig ID. 

To note while the step at part 6 was successful in producing a combined dataset with the contig ID column it wasn't possible when handling larger files which was the case with Actinobacteria, Firmicutes and Proteobacteria. On my current PC the awk command would freeze and have to be killed after a certain duration. As such I had to opt for a more simple method. In this case the gene annotation and EGGNOG annotation files were both sorted by their gene IDs. These files were then join by the gene ID with the relevant headers re-added to the end tsv file. The commands for this alternative method are outlined below in the case of Firmicutes. Note that they were repeated exactly the same for Proteobacteria and Actinobacteria.

1) sort -T . -k1,1 phylum-Firmicutes.gene_annotations.filtered.tsv -o sorted_phylum-Firmicutes.gene_annotations.filtered.tsv
sort -T . -k1,2 Firmicutes.dataset.tsv -o sorted_Firmicutes.dataset.tsv

2) join -t $'\t' -1 2 -2 1 sorted_Firmicutes.dataset.tsv sorted_phylum-Firmicutes.gene_annotations.filtered.tsv > joined_file.tsv

3) echo -e "$(head -n 1 Firmicutes.dataset.tsv)\tScore" > final_output.tsv
cat joined_file.tsv >> final_output.tsv 

Once all 5 datasets for each phylum were produced the were concatenated using the following command

7) awk 'FNR==1 && NR!=1 {next} {print}' Euryarchaeota.tsv Bacteriodetes.tsv Actinobacteria.tsv Firmicutes.tsv Proteobacteria.tsv > master_dataset.tsv

This ensured the headers remaining consistent to the intended layout in the Euryarchaeota dataset

8) awk -F'\t' '{
  split($1, a, /\./);
  new_col = a[2];
  for (i=3; i<=length(a); i++) {
    new_col = new_col "." a[i];
  }
  print $0 "\t" new_col
}' Dataset.tsv > output.tsv

This command removed the Biosample ID from the first column of our dataset and added it to a new column corresponding to each row's biosample.

9) awk -F'\t' 'NR==1{$2="GTDB_BIOSAMPLE"}1' OFS='\t' output.tsv > temp.tsv && mv temp.tsv Final_dataset.tsv

This final command added a title to the final column denoting it as representing the GTDB biosample. For more efficient later coding the results obtained from the dataset can be searched against the GTDB biosample tsv file. Appending the GTDB file would have greatly increased the size of the Master dataset
